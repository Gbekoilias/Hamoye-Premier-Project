{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f9ed6f6",
   "metadata": {},
   "source": [
    "# Topic: Climate-Resilient Farming Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03951d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07a41a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Argricultural Survey data\n",
    "raw_data = pd.read_csv('./Dataset/data.csv', low_memory=False)\n",
    "raw_data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23737009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store names of columns externally to select needed columns\n",
    "with open('columns.txt', 'w') as file:\n",
    "    for item in raw_data.columns:\n",
    "        file.write('%s\\n' % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ab6e3f",
   "metadata": {},
   "source": [
    "# Section information\n",
    "\n",
    "Section 1: Household Roster--Members of Households and Education\n",
    "Section 2: Employment\n",
    "Section 3: Tenure Issues and Labor Composition\n",
    "Section 4: Details on Farming Activities\n",
    "Section 5: Access and Extension Services \n",
    "Section 6: Other Farming Costs and Farm Subsidies\n",
    "Section 7: Adaptation Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cff1477",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a list of relevant section files containing section columns\n",
    "sections = ['section_3_col.txt', 'section_4_col.txt', 'section_7_col.txt']\n",
    "sec_cols = {}\n",
    "# Iterate through the list of section file names\n",
    "for file_name in sections:\n",
    "    # Open the txt file in read mode\n",
    "    with open(file_name, 'r') as file:\n",
    "        # Read lines from the file and create a list\n",
    "        columns = [column.strip() for column in file.readlines()]\n",
    "        # Remove the '.txt' extension and save the list with the corresponding file name\n",
    "        sec_cols[file_name[:-4]] = columns\n",
    "# Print the list of columns needed    \n",
    "print(sec_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca6d0878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of each section's columns using the key(section name) as the identifies and values(column names) as items in the list\n",
    "# Iterate through the dictionary items\n",
    "for key, value in sec_cols.items():\n",
    "    # Create variables with key names and assign them the corresponding list values\n",
    "    locals()[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e588d7d9",
   "metadata": {},
   "source": [
    "## Section 3 - Tenure issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c19aaacf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filter raw data to contain columns needed for section 3\n",
    "tenure_data = raw_data[section_3_col]\n",
    "# Print tenure_data\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(tenure_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "289ff233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of NaN values in each column\n",
    "na_percentage = (tenure_data.isna().mean() * 100)\n",
    "\n",
    "# Drop columns with more than 80% NaN values\n",
    "columns_to_drop = na_percentage[na_percentage > 80].index\n",
    "tenure_data = tenure_data.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5ecfbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sum of missing data in each column\n",
    "tenure_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2a37c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm all plot areas are in the same unit\n",
    "tenure_data['plotunits'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "189da4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tenure_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13aadf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dataframe to contain selected tenure features\n",
    "tenure_features = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49bcb197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of streamlined columns\n",
    "columns =['hhcode', 'adm0', 'adm1', 'farmtype', 'fplotarea1', 'fsystem1',\n",
    "       'tenure1', 'yearsuse1', 'rentplot1', 'season1s', 'season1e', 'season2s', 'season2e', 'seas1nam', 'seas2nam']\n",
    "# Filter the tenure_data to store streamlined columns in tenure_features\n",
    "tenure_features = tenure_data[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69dea75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get value_counts of the columns to spot odd values\n",
    "cat_cols = tenure_features.columns\n",
    "for col in cat_cols:\n",
    "    print(tenure_features[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5179c560",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tenure_features['adm1'] = tenure_features['adm1'].str.lower()\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    print(tenure_features.groupby('adm0')['adm1'].value_counts(dropna=False).sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96d39111",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tenure_features['adm1'] = tenure_features['adm1'].replace('bborng-ahafo','brong-ahafo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad153513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert odd values not within categotical range to 'Other', 5\n",
    "tenure_features.loc[:, 'fsystem1'] = tenure_features['fsystem1'].apply(lambda x: x if (x in range(1, 7) or pd.isna(x)) else 5)\n",
    "\n",
    "# Convert odd values not within categotical range to 'Other', 7\n",
    "tenure_features.loc[:, 'tenure1'] = tenure_features['tenure1'].apply(lambda x: x if (x in range(1, 8) or pd.isna(x)) else 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fc306b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tenure_features['seas1nam'] = tenure_features['seas1nam'].str.lower()\n",
    "tenure_features['seas2nam'] = tenure_features['seas2nam'].str.lower()\n",
    "\n",
    "replacements = {\n",
    "    'long rain' : 'long rains',\n",
    "    'short rain' : 'short rains',\n",
    "    '0' : 'others',\n",
    "    '3' : 'others',\n",
    "    '3meher' : 'others',\n",
    "    '3 meher' : 'others',\n",
    "    'beley' : 'others',\n",
    "    'belg' : 'others',\n",
    "    '3-meher' : 'others',\n",
    "    '3,1beley' : 'others',\n",
    "    'oct' : 'others',\n",
    "    '4' : 'others',\n",
    "    'belg3,1' : 'others',\n",
    "    '2-belg' : 'others',\n",
    "    '1belge' : 'others',\n",
    "    '99' : 'others',\n",
    "    'belg(1)' : 'others',\n",
    "    '3belg' : 'others',\n",
    "    '2- belg' : 'others',\n",
    "    '1,2' : 'others',\n",
    "    '999' : 'others'\n",
    "}\n",
    "tenure_features['seas1nam'] = tenure_features['seas1nam'].replace(replacements)\n",
    "tenure_features['seas2nam'] = tenure_features['seas2nam'].replace(replacements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bace5cc4",
   "metadata": {},
   "source": [
    "## Section 4 - Details on Farming Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f93ad146",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filter raw data to contain columns needed for section 4\n",
    "crop_data = raw_data[section_4_col]\n",
    "\n",
    "# Print tenure_data\n",
    "print(crop_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "264a4095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sum of missing data in each column\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    print(crop_data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62ffabef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use regex to drop columns not needed\n",
    "import re\n",
    "\n",
    "# Define regex partern to match columns to drop\n",
    "regex_pattern = r's3|p2|c2|c3|c4|c5|c6'\n",
    "\n",
    "#use filter and regex to drop columns matching the pattern\n",
    "plot_cols = [col for col in crop_data.columns if re.search(regex_pattern, col)]\n",
    "crop_data = crop_data.drop(columns=plot_cols)\n",
    "print(plot_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b3cae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of NaN values in each column\n",
    "na_percentage = (crop_data.isna().mean() * 100)\n",
    "\n",
    "# Drop columns with more than 80% NaN values\n",
    "columns_to_drop = na_percentage[na_percentage > 80].index\n",
    "crop_data = crop_data.drop(columns=columns_to_drop)\n",
    "\n",
    "print(crop_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b0b86df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(crop_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cab643d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dataframe, crop_features to contain selected tenure features\n",
    "crop_features = pd.DataFrame()\n",
    "crop_features = crop_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4612094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get value_counts of the binary columns to spot odd values not 1/0/1.0/0.0\n",
    "cat_cols = crop_features.columns\n",
    "for col in cat_cols:\n",
    "    print(crop_features[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3340db44",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_crop_cols = ['s1p1c1', 's2p1c1', 'pc1']\n",
    "for col in cat_crop_cols:\n",
    "    # Convert odd values not within categotical range to 'Other', 56\n",
    "    crop_features.loc[:, col] = crop_features[col].apply(lambda x: x if (x in range(1, 57) or pd.isna(x)) else 56)\n",
    "\n",
    "cat_mkt_col = ['s1p1c1mkt', 's2p1c1mkt']\n",
    "for col in cat_crop_cols:\n",
    "    # Convert odd values not within categotical range to 'Other', 7\n",
    "    crop_features.loc[:, col] = crop_features[col].apply(lambda x: x if (x in range(1, 8) or pd.isna(x)) else 7)\n",
    "    \n",
    "crop_features.loc[:, 'transport'] = crop_features['transport'].apply(lambda x: x if (x in range(1, 7) or pd.isna(x)) else 6)\n",
    "\n",
    "cat_wat_col = ['s1p1wat1', 's1p1wat2', 's1p1wat3', 's1p1wat4', 's1p1wat5']\n",
    "for col in cat_crop_cols:\n",
    "    # Convert odd values not within categotical range to 'Other', 5\n",
    "    crop_features.loc[:, col] = crop_features[col].apply(lambda x: x if (x in range(1, 6) or pd.isna(x)) else 5)\n",
    "\n",
    "cat_irrig_col = ['s1p1irrig1', 's1p1irrig2', 's1p1irrig3', 's1p1irrig4']\n",
    "for col in cat_crop_cols:\n",
    "    # Convert odd values not within categotical range to 'Other', 4\n",
    "    crop_features.loc[:, col] = crop_features[col].apply(lambda x: x if (x in range(1, 5) or pd.isna(x)) else 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4422672",
   "metadata": {},
   "source": [
    "## Section 7- Climate Adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "537d2909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter raw data to contain columns needed\n",
    "climate_data = raw_data[section_7_col]\n",
    "# Print tenure_data\n",
    "print(climate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0eff2d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of NaN values in each column\n",
    "na_percentage = (climate_data.isna().mean() * 100)\n",
    "\n",
    "# Drop columns with more than 80% NaN values\n",
    "columns_to_drop = na_percentage[na_percentage > 80].index\n",
    "climate_data = climate_data.drop(columns=columns_to_drop)\n",
    "\n",
    "print(climate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1986ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sum of missing data in each column\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    print(climate_data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9868596d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get value_counts of the binary columns to spot odd values not 1/0/1.0/0.0\n",
    "for col in climate_data.columns[2:]:\n",
    "    print(climate_data[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0054ad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_columns = climate_data.columns[2:]\n",
    "\n",
    "def binary_convert(column):\n",
    "    try:\n",
    "        value = int(column)\n",
    "        if value in [1, 0]:\n",
    "            return value\n",
    "        else:\n",
    "            return np.nan\n",
    "    except (ValueError, TypeError):\n",
    "        return np.nan\n",
    "\n",
    "for column in binary_columns:\n",
    "    # Convert non-binary values to NaN\n",
    "    climate_data[column] = climate_data[column].apply(binary_convert)\n",
    "\n",
    "# All columns have binary values in the format 1 and 0, handling odd digits\n",
    "print(climate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bddd6f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dataframe to contain selected tenure features\n",
    "climate_features = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59a9bc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_features = climate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4aede81",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08ab63bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_features.to_csv('climate_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c127509",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.merge(pd.merge(tenure_features, crop_features, on='hhcode'), climate_features, on='hhcode', how='right')\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8730bcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61cfd2a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None):\n",
    "    print(all_data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b74e4c81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get value_counts of the columns inspect\n",
    "columns = all_data.columns\n",
    "for col in columns:\n",
    "    print(all_data[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "55ce5c73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(columns[:77])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "999d34cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "def extract_month(date_string):\n",
    "    try:\n",
    "        parsed_date = parser.parse(date_string)\n",
    "        month_name = parsed_date.strftime('%B')  # Extract full month name\n",
    "        return month_name\n",
    "    except (TypeError, ValueError):\n",
    "        return pd.NA  # Return NaN for invalid dates\n",
    "\n",
    "# Apply the function to the date columns and extract the month\n",
    "date_cols = ['season1s', 'season1e', 'season2s', 'season2e', 's1p1c1plant', 's1p1c1harv', 's2p1c1plant', 's2p1c1harv']\n",
    "for col in date_cols:\n",
    "    all_data[col] = all_data[col].apply(extract_month)\n",
    "\n",
    "# Print the DataFrame with extracted months and NaN for invalid dates\n",
    "print(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "16b969a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pattern to remove from column names\n",
    "patterns_to_remove = ['p1c1', 'p1']\n",
    "\n",
    "# Get the list of columns to process\n",
    "columns_to_process = all_data.columns\n",
    "\n",
    "# Remove the specified patterns from column names\n",
    "new_columns = [col for col in columns_to_process]\n",
    "for pattern in patterns_to_remove:\n",
    "    new_columns = [col.replace(pattern, '') for col in new_columns]\n",
    "\n",
    "# Rename the columns in the DataFrame\n",
    "all_data.columns = new_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9dc76e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.columns[:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "68224a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = all_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "84b56853",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_replacement_dict = {\n",
    "    0 : 5\n",
    "}\n",
    "\n",
    "irrig_replacement_dict = {\n",
    "    0 : 4\n",
    "}\n",
    "\n",
    "market_replacement_dict = {\n",
    "    0 : 3\n",
    "}\n",
    "\n",
    "seasname_replacement_dict = {\n",
    "    '-99' : pd.NA,\n",
    "    '-999' : pd.NA,\n",
    "    '.' : 3\n",
    "}\n",
    "\n",
    "\n",
    "# Replace column values using the replacement dictionaries\n",
    "water_col = ['s1wat1', 's1wat2', 's1wat3', 's1wat4', 's1wat5', 's2wat1', 's2wat2', 's2wat3', 's2wat4', 's2wat5']\n",
    "irrig_col = ['s1irrig1', 's1irrig2', 's1irrig3', 's1irrig4', 's2irrig1', 's2irrig2', 's2irrig3', 's2irrig4']\n",
    "season_col = ['seas1nam', 'seas2nam']\n",
    "market_col = ['s1mkt', 's2mkt']\n",
    "for col in water_col:\n",
    "    model_data[col] = model_data[col].replace(water_replacement_dict)\n",
    "for col in irrig_col:\n",
    "    model_data[col] = model_data[col].replace(irrig_replacement_dict)\n",
    "for col in season_col:\n",
    "    model_data[col] = model_data[col].replace(seasname_replacement_dict)\n",
    "for col in market_col:\n",
    "    model_data[col] = model_data[col].replace(market_replacement_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "124f73b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = {\n",
    "    'adm0' : 'Country',\n",
    "    'adm1' : 'Region',\n",
    "    'season1s' : 's1start',\n",
    "    'season1e' : 's1end',\n",
    "    'season2s' : 's2start',\n",
    "    'season2e' : 's2end',\n",
    "    's1' : 'crop1',\n",
    "    's1plant' : 's1plant_data',\n",
    "    's1harv' : 's1harv_date',\n",
    "    's1area' : 's1land_area',\n",
    "    's1qharv' : 's1quant_harv',\n",
    "    's1cons' : 's1consumed',\n",
    "    's1lives' : 's1livestock',\n",
    "    's1lost' : 's1lost',\n",
    "    's1mkt' : 's1market',\n",
    "    's1sold' : 's1quant_sold',\n",
    "    's1cval' : 's1crop_val',\n",
    "    's1seed' : 's1no_seed',\n",
    "    's1sval' : 's1seed_cost',\n",
    "        's2' : 'crop2',\n",
    "    's2plant' : 's2plant_data',\n",
    "    's2harv' : 's2harv_date',\n",
    "    's2area' : 's2land_area',\n",
    "    's2qharv' : 's2quant_harv',\n",
    "    's2cons' : 's2consumed',\n",
    "    's2lives' : 's2livestock',\n",
    "    's2lost' : 's2lost',\n",
    "    's2mkt' : 's2market',\n",
    "    's2sold' : 's2quant_sold',\n",
    "    's2cval' : 's2crop_val',\n",
    "    's2seed' : 's2no_seed',\n",
    "    's2sval' : 's2seed_cost'\n",
    "}\n",
    "\n",
    "model_data.rename(columns = column_mapping, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d37e2aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data.to_csv('./Dataset/model_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e5585951",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_data = all_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ccffd534",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_data.columns[:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5849347",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dictionary with replacement column names\n",
    "crop_replacement_dict = {\n",
    "    1 : 'alfalfa',\n",
    "    2 : 'banana',\n",
    "    3 : 'barley',\n",
    "    4 : 'beans',\n",
    "    5 : 'cashew',\n",
    "    6 : 'cassava',\n",
    "    7 : 'citrus fruit',\n",
    "    8 : 'chickpeas',\n",
    "    9 : 'clover',\n",
    "    10 : 'cocoa',\n",
    "    11 : 'cocoyam',\n",
    "    12 : 'cowpea',\n",
    "    13 : 'coffee',\n",
    "    14 : 'cotton',\n",
    "    15 : 'cucumber',\n",
    "    16 : 'enset',\n",
    "    17 : 'field pea',\n",
    "    18 : 'flax',\n",
    "    19 : 'garden-eggs',\n",
    "    20 : 'garlic',\n",
    "    21 : 'grape',\n",
    "    22 : 'groundnut',\n",
    "    23 : 'kola',\n",
    "    24 : 'lentil',\n",
    "    25 : 'mango',\n",
    "    26 : 'maize',\n",
    "    27 : 'millet',\n",
    "    28 : 'oil palm',\n",
    "    29 : 'okra',\n",
    "    30 : 'onion',\n",
    "    31 : 'palm dates',\n",
    "    32 : 'paprika',\n",
    "    33 : 'peanuts',\n",
    "    34 : 'pepper',\n",
    "    35 : 'pigeon pea',\n",
    "    36 : 'pineapple',\n",
    "    37 : 'plantain',\n",
    "    38 : 'potato',\n",
    "    39 : 'rice',\n",
    "    40 : 'safflower',\n",
    "    41 : 'sesame',\n",
    "    42 : 'shallots',\n",
    "    43 : 'sheanut',\n",
    "    44 : 'sorghum',\n",
    "    45 : 'soybean',\n",
    "    46 : 'spinach',\n",
    "    47 : 'squash',\n",
    "    48 : 'sugarcane',\n",
    "    49 : 'sunflower',\n",
    "    50 : 'tea',\n",
    "    51 : 'tef',\n",
    "    52 : 'tobacco',\n",
    "    53 : 'tomato',\n",
    "    54 : 'wheat',\n",
    "    55 : 'yam',\n",
    "    56 : 'other'\n",
    "}\n",
    "\n",
    "water_replacement_dict = {\n",
    "    1 : 'irrigated major scheme',\n",
    "    2 : 'irrigated minor scheme',\n",
    "    3 : 'irrigated groundwater',\n",
    "    4 : 'rain-fed',\n",
    "    5 : 'other',\n",
    "    0 : 'other'\n",
    "}\n",
    "\n",
    "irrig_replacement_dict = {\n",
    "    1 : 'gravity',\n",
    "    2 : 'sprinklers',\n",
    "    3 : 'drip systems',\n",
    "    4 : 'other',\n",
    "    0 : 'other'\n",
    "}\n",
    "\n",
    "market_replacement_dict = {\n",
    "    1 : 'Directly to consumers',\n",
    "    2 : 'Middleman/wholesale',\n",
    "    3 : 'Other',\n",
    "    4 : 'Combination',\n",
    "    0 : 'Other'\n",
    "}\n",
    "\n",
    "seasname_replacement_dict = {\n",
    "    '1' : 'winter season',\n",
    "    '2' : 'summer season',\n",
    "    '3' : 'others',\n",
    "    '-99' : pd.NA,\n",
    "    '-999' : pd.NA,\n",
    "    '.' : 'other'\n",
    "}\n",
    "\n",
    "tenure_replacement_dict = {\n",
    "    1 : 'Own land and use',\n",
    "    2 : 'Own land and rent',\n",
    "    3 : 'Sharecropped land',\n",
    "    4 : 'Communal land',\n",
    "    5 : 'Rented land',\n",
    "    6 : 'Borrowed land',\n",
    "    7 : 'Other',\n",
    "}\n",
    "\n",
    "farmsys_replacement_dict = {\n",
    "    1 : 'Shifting cultivation',\n",
    "    2 : 'Continuous cropping',\n",
    "    3 : 'CC with multiple rotations',\n",
    "    4 : 'Livestock grazing land',\n",
    "    5 : 'Other',\n",
    "    6 : 'Combination',\n",
    "\n",
    "}\n",
    "\n",
    "farmtype_replacement_dict = {\n",
    "    1: 'small-scale',\n",
    "    2: 'medium scale',\n",
    "    3: 'large-scale',\n",
    "}\n",
    "\n",
    "transport_replacement_dict = {\n",
    "    1 : 'walk',\n",
    "    2 : 'animal',\n",
    "    3 : 'cart/bicycle',\n",
    "    4 : 'motorized vehicle',\n",
    "    6 : 'combination',\n",
    "    6 : 'other',\n",
    "}\n",
    "\n",
    "\n",
    "# Replace column values using the replacement dictionaries\n",
    "crop_col = ['s1', 's2', 'pc1']\n",
    "water_col = ['s1wat1', 's1wat2', 's1wat3', 's1wat4', 's1wat5', 's2wat1', 's2wat2', 's2wat3', 's2wat4', 's2wat5']\n",
    "irrig_col = ['s1irrig1', 's1irrig2', 's1irrig3', 's1irrig4', 's2irrig1', 's2irrig2', 's2irrig3', 's2irrig4']\n",
    "season_col = ['seas1nam', 'seas2nam']\n",
    "market_col = ['s1mkt', 's2mkt']\n",
    "for col in crop_col:\n",
    "    analysis_data[col] = analysis_data[col].replace(crop_replacement_dict)\n",
    "for col in water_col:\n",
    "    analysis_data[col] = analysis_data[col].replace(water_replacement_dict)\n",
    "for col in irrig_col:\n",
    "    analysis_data[col] = analysis_data[col].replace(irrig_replacement_dict)\n",
    "for col in season_col:\n",
    "    analysis_data[col] = analysis_data[col].replace(seasname_replacement_dict)\n",
    "for col in market_col:\n",
    "    analysis_data[col] = analysis_data[col].replace(market_replacement_dict)\n",
    "analysis_data['fsystem1'] = analysis_data['fsystem1'].replace(farmsys_replacement_dict)\n",
    "analysis_data['tenure1'] = analysis_data['tenure1'].replace(tenure_replacement_dict)\n",
    "analysis_data['farmtype'] = analysis_data['farmtype'].replace(tenure_replacement_dict)\n",
    "analysis_data['transport'] = analysis_data['transport'].replace(tenure_replacement_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9ea53d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get value_counts of the columns to inspect\n",
    "columns = analysis_data.columns\n",
    "for col in columns:\n",
    "    print(analysis_data[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7230d499",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_data.to_csv('./Dataset/analysis_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aacec5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
